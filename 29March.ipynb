{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54b488ce-9dfd-4316-9887-f07c9111c507",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4292294800.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    Lasso Regression, also known as L1 regularization, is a linear regression technique used for feature selection and regularization.\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Ans1.\n",
    "Lasso Regression, also known as L1 regularization, is a linear regression technique used for feature selection and regularization.\n",
    "\n",
    "In Lasso Regression, the goal is to minimize the sum of squared residuals (similar to OLS), but with an additional term called the L1 penalty. \n",
    "The key difference between Lasso Regression and other regression techniques, such as Ridge Regression, lies in the penalty term. Lasso Regression uses an L1 penalty, which results in sparse solutions where only a subset of the coefficients is non-zero. This is in contrast to Ridge Regression, which uses an L2 penalty that forces the coefficients to be small but rarely zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ba5a99-8066-4ae9-ad72-d75ef4de4929",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans2.\n",
    "Adavantages of Lasoo regression\n",
    "1.It can be used to select features even when there is a large number of features.\n",
    "2.It can be used to select features that are correlated with each other.\n",
    "3.It can be used to select features that are important for predicting the outcome variable, even if they are not statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ce128e-abc7-4a04-9336-71f73cad0462",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans3.\n",
    "Interpreting the coefficients of a Lasso Regression model can be slightly different from interpreting the coefficients of other regression models due to the L1 penalty and the possibility of sparse solutions. \n",
    "\n",
    "We can intepret the coefficients of a Lasso Regression model by :\n",
    "    1.Non-zero coefficients\n",
    "    2.Zero coefficients\n",
    "    3.Magnitude of coefficients\n",
    "    4.Interaction and nonlinear effects:\n",
    "    5.Regularization parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353f186b-ba2e-4f08-91b6-4d891259efce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans4.\n",
    "In Lasso Regression, there are two main tuning parameters that can be adjusted to control the model's behavior and performance:\n",
    "\n",
    "1.Lambda (Î±): Lambda, also known as the regularization parameter or penalty term, controls the amount of penalty applied to the coefficients in Lasso Regression. It determines the trade-off between the sum of squared residuals and the L1 penalty. Higher values of lambda result in stronger penalty, leading to more coefficients being shrunk towards zero and sparser solutions. \n",
    "2.Feature scaling: Although not a tuning parameter specific to Lasso Regression, feature scaling can have an impact on the model's performance. Since Lasso Regression involves regularization, the scale of the features can influence the penalty and the resulting coefficients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30af0e94-4652-4ec3-bf33-3ca6916837b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans5.\n",
    "Lasso Regression, in its original form, is a linear regression technique that assumes a linear relationship between the predictors and the target variable. \n",
    "\n",
    "Yes, Lasso regression can be used for non-linear regression problems. However, it is important to note that Lasso regression is a linear model, and as such, it will only be able to approximate the non-linear relationship between the independent and dependent variables.\n",
    "\n",
    "There are a few ways to use Lasso regression for non-linear regression problems. One way is to transform the independent variables into a non-linear space. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c558c73-5854-4fcb-97c6-dac4abf36952",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans6.\n",
    "Ridge Regression\n",
    "1.Does not eliminate any features.\n",
    "2.More computationally efficient.\n",
    "3.Performs better when there are many small to medium-sized coefficients.\n",
    "4.Requires setting a hyperparameter\n",
    "5.Shrinks the coefficients toward zero\n",
    "\n",
    "Lasso Regression\n",
    "1.Can eliminate some features.\n",
    "2.Less computationally efficient.\n",
    "3.Performs better when there are a few large coefficients.\n",
    "4.Requires setting a hyperparameter.\n",
    "5.Encourages some coefficients to be exactly zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1e8516-79dc-4337-b442-08973f4aad14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans7.\n",
    "Yes, Lasso Regression can handle multicollinearity, which is the presence of highly correlated input features.\n",
    "\n",
    "Lasso regression addresses this problem by adding a penalty term to the model's loss function that is proportional to the absolute value of each coefficient. This penalty term encourages some of the coefficients to be zero, which means that those features will be excluded from the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fec68e-4671-42e8-83ff-38d866432ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans8.\n",
    "Choosing the optimal value of the regularization parameter (lambda) in Lasso Regression is crucial for obtaining the best model performance\n",
    "\n",
    "There are some approaches to select the optimal value of lambda:\n",
    "1.Cross-validation\n",
    "2.Grid search\n",
    "3.Information criteria"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
