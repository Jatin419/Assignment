{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3050d532-e145-4523-a529-ca84528d11fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans1.\n",
    "Elastic net regression is a type of regularized regression that combines the L1 and L2 penalties of lasso and ridge regression. This means that it can shrink the coefficients of less important features to zero, like lasso regression, while also preventing the coefficients of important features from becoming too large, like ridge regression.\n",
    "\n",
    "Elastic Net Regression differs from other regression techniques:\n",
    "    1.Ridge Regression (L2 Regularization):Ridge Regression adds a penalty term proportional to the square of the magnitude of the coeffi\n",
    "      cients (L2 norm) to the ordinary least squares objective function. \n",
    "        \n",
    "    2.Lasso Regression (L1 Regularization) :Lasso Regression, similar to Ridge Regression, adds a penalty term to the objective function.\n",
    "    \n",
    "    3.Elastic Net Regression (Combination of L1 and L2 Regularization):\n",
    "      Elastic Net Regression combines the L1 and L2 regularization techniques of Ridge and Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f99957a-c4f1-43ac-a504-882821d70196",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans2.\n",
    "Choosing the optimal values of the regularization parameters for Elastic Net Regression involves finding a balance between the L1 and L2 penalties.\n",
    "\n",
    "Alpha (α): Alpha controls the overall regularization strength in Elastic Net Regression. It is a value between 0 and 1\n",
    "Lambda (λ): Lambda represents the specific amount of regularization applied to the model. It determines the magnitude of the coefficients' shrinkage.\n",
    "\n",
    "some approaches you can follow to choose the optimal values for these hyperparameters:\n",
    "    1.Start with a small value for the regularization parameter\n",
    "    2.Increase the regularization parameter gradually\n",
    "    3.Use a validation set\n",
    "    4.Try different values for the l1_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba686e99-40bd-4b44-a8a2-0c08387208db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans3.\n",
    "\n",
    "Elastic net regression is a type of regularized regression that combines the L1 and L2 penalties of lasso and ridge regression.\n",
    "\n",
    "Advantages:\n",
    "    1.Variable Selection: Elastic Net Regression combines L1 and L2 regularization, allowing for both coefficient shrinkage and variable selection.\n",
    "    2.Robustness to Multicollinearity: Elastic Net Regression handles multicollinearity better than Ridge Regression.\n",
    "    3.Can reduce bias and variance: Elastic net regression can reduce both bias and variance, which can lead to a more accurate model.\n",
    "\n",
    "Disadvantages:\n",
    "    1.Can be computationally expensive: Elastic net regression can be more computationally expensive than lasso or ridge regression.\n",
    "    2.Can be difficult to interpret: The coefficients of an elastic net regression model can be difficult to interpret, as they are a combination of the L1 and L2 penalties.\n",
    "    3.Increased Complexity: Elastic Net Regression introduces additional complexity compared to standard linear regression.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f046c1f-6c78-48f6-929a-0f443fedc795",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans4.\n",
    "\n",
    "Elastic net regression is a popular choice for regression problems where there is a risk of overfitting. It can also be used to select features.\n",
    "\n",
    "Uses cases-\n",
    "-->High-Dimensional Data\n",
    "-->Multicollinearity\n",
    "-->Feature Selection\n",
    "-->Natural language processing\n",
    "-->Marketing Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329b4d41-ae19-4b33-92dc-bab0e8aa7097",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans5.\n",
    "Interpreting the coefficients in Elastic Net Regression can be more challenging than in traditional linear regression due to the combination of L1 and L2 regularization.\n",
    "\n",
    "Non-Zero Coefficients: The non-zero coefficients indicate the variables that are deemed important by the Elastic Net Regression model.\n",
    "Magnitude of Coefficients: The magnitude of the coefficients reflects the extent of the impact of each predictor on the predicted outcome\n",
    "Coefficient Sign: The sign of a coefficient indicates the direction of the relationship between a predictor variable and the target variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a2c39d-c501-4bfd-ac68-6b5b753e2f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans6.\n",
    "\n",
    "There are a few different ways to handle missing values when using elastic net regression.\n",
    "\n",
    "Deletion of Missing Data: One simple approach is to remove observations with missing values entirely. \n",
    "Mean/Mode Imputation: Replace missing values with the mean (for numeric variables) or mode (for categorical variables) of the corresponding variable\n",
    "Median Imputation: Similar to mean imputation, missing values can be replaced with the median value of the variable. \n",
    "Multiple Imputation: Multiple imputation involves creating multiple imputed datasets, where missing values are imputed multiple times based on observed values and their relationships. \n",
    "Missing Indicator Variables: Create binary indicator variables that flag whether a value is missing or not for each predictor variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ab76a5-f96f-42b5-9a69-d2a458ee89ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans7.\n",
    "Elastic net regression can be used for feature selection by shrinking the coefficients of less important features to zero\n",
    "\n",
    "The steps involved in using elastic net regression for feature selection:\n",
    "\n",
    "-->Fit an elastic net regression model to the data.\n",
    "-->Set the l1_ratio parameter to a value between 0 and 1.\n",
    "-->Look at the coefficients of the model. The coefficients that are not shrunk to zero are likely to be important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37be027-cb49-440c-a839-fea1c90bfb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans8.\n",
    "import pickle\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# Train the model\n",
    "model = ElasticNet()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Pickle the model\n",
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "# Unpickle the model\n",
    "with open('model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1f448f-1d84-4c29-8741-7c8b7aac8396",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans9.\n",
    "The purpose of pickling a model in machine learning is to save the model so that it can be used later. \n",
    "\n",
    "Deploying the model: If you want to deploy the model to a production environment, you will need to pickle it so that you can load it into the production environment.\n",
    "Sharing the model: If you want to share the model with others, you can pickle it and send the pickled model to them.\n",
    "Reusing the model: If you want to use the model again in the future, you can pickle it and save it for later.\n",
    "\n",
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create a model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Pickle the model\n",
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
